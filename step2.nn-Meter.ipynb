{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b109737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii import model_wrapper\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Device configuration\n",
    "#\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "if num_gpus >= 2:\n",
    "    # Select the second GPU (index 1)\n",
    "    device = torch.device(\"cuda:1\")\n",
    "else:\n",
    "    # If there are not enough GPUs, use the first one (index 0) or CPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f83963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "@model_wrapper\n",
    "class ResNet_(nn.Module):\n",
    "    def __init__(self, num_channel_1, kernel_sizes, strides, paddings, kernel_size_pool, stride_size_pool, poolchoice, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model_name = 'resnet'\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(NUM_FEATURES, num_channel_1, kernel_size=kernel_sizes, stride=strides, padding=paddings, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_channel_1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.poolchoice = [nn.MaxPool2d(kernel_size=kernel_size_pool, stride=stride_size_pool, padding=1),\n",
    "                           nn.Identity()][poolchoice]\n",
    "        \n",
    "        num_channel_2 = num_channel_1*2\n",
    "        num_channel_3 = num_channel_2*2\n",
    "        num_channel_4 = num_channel_3*2\n",
    "\n",
    "        ### layer1\n",
    "        self.block1 = self.make_block(num_channel_1, num_channel_1, 1)\n",
    "        self.block2 = self.make_block(num_channel_1, num_channel_1, 1)\n",
    "        ### layer2\n",
    "        self.block3 = self.make_block(num_channel_1, num_channel_2, 2)\n",
    "        self.block4 = self.make_block(num_channel_2, num_channel_2, 1)\n",
    "        ### layer3\n",
    "        self.block5 = self.make_block(num_channel_2, num_channel_3, 2)\n",
    "        self.block6 = self.make_block(num_channel_3, num_channel_3, 1)\n",
    "        ### layer4\n",
    "        self.block7 = self.make_block(num_channel_3, num_channel_4, 2)\n",
    "        self.block8 = self.make_block(num_channel_4, num_channel_4, 1)\n",
    "        \n",
    "        ### downsample\n",
    "        self.ds2 = nn.Sequential(nn.Conv2d(num_channel_1, num_channel_2, kernel_size=1, stride=2, bias=False),\n",
    "                                 nn.BatchNorm2d(num_channel_2))\n",
    "        self.ds3 = nn.Sequential(nn.Conv2d(num_channel_2, num_channel_3, kernel_size=1, stride=2, bias=False),\n",
    "                                 nn.BatchNorm2d(num_channel_3))\n",
    "        self.ds4 = nn.Sequential(nn.Conv2d(num_channel_3, num_channel_4, kernel_size=1, stride=2, bias=False),\n",
    "                                 nn.BatchNorm2d(num_channel_4))\n",
    "        \n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc = nn.Linear(num_channel_4, num_classes)\n",
    "\n",
    "    def make_block(self, inplanes, planes, stride=1):\n",
    "        conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        bn1 = nn.BatchNorm2d(planes)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        bn2 = nn.BatchNorm2d(planes)\n",
    "        basicblock = []\n",
    "        basicblock += [conv1, bn1, relu, conv2, bn2]\n",
    "        return nn.Sequential(*basicblock)\n",
    "           \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.poolchoice(x)\n",
    "        x1 = self.block1(x) + x\n",
    "        x1 = self.block2(x1) + x1\n",
    "        x2 = self.ds2(x1) + self.block3(x1)\n",
    "        x2 = self.block4(x2) + x2\n",
    "        x3 = self.ds3(x2) + self.block5(x2)\n",
    "        x3 = self.block6(x3) + x3\n",
    "        x4 = self.ds4(x3) + self.block7(x3)\n",
    "        x4 = self.block8(x4) + x4\n",
    "        x = self.adaptivepool(x4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf51f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nn_meter\n",
    "print(f\"nn_meter version: {nn_meter.__version__}\")\n",
    "\n",
    "# list all supporting latency predictors\n",
    "predictors = nn_meter.list_latency_predictors()\n",
    "for p in predictors:\n",
    "    print(f\"[Predictor] {p['name']}: version={p['version']}\")\n",
    "predictor_names = [p['name'] for p in predictors]\n",
    "predictors = [nn_meter.load_latency_predictor(p['name'], 1.0) for p in predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8fcc60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_latency(re_path, in_channels, batch_s, predictor):\n",
    "    nni_re = pd.read_csv(re_path)\n",
    "    input_shape = (batch_s, in_channels, 100, 100)\n",
    "\n",
    "    lats = np.zeros(len(nni_re))\n",
    "    sizes = np.zeros(len(nni_re))\n",
    "    for i in range(len(nni_re)):\n",
    "        t = nni_re.mutation[i].replace(\"'\", \"\\\"\")\n",
    "        d = json.loads(t)\n",
    "        model = ResNet_(num_channel_1=d['num_channel'], \n",
    "                        kernel_sizes=d['kernel_size'], \n",
    "                        strides=d['stride'], \n",
    "                        paddings=d['padding'], \n",
    "                        kernel_size_pool=d['kernel_size_pool'], \n",
    "                        stride_size_pool=d['stride_size_pool'], \n",
    "                        poolchoice=int(d['poolchoice'])).to(device)\n",
    "\n",
    "        dummy_input = torch.randn(batch_s, in_channels, 100, 100).to(device)\n",
    "        torch.onnx.export(model, dummy_input, \"temp.onnx\")\n",
    "        size = os.path.getsize(\"temp.onnx\")\n",
    "        sizes[i] = size\n",
    "        \n",
    "        lat = predictor.predict(model, model_type='torch', input_shape=input_shape, apply_nni=False) \n",
    "        lats[i] = lat\n",
    "    return (lats, sizes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11810d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_re = pd.DataFrame()\n",
    "\n",
    "lats = []\n",
    "sizes = []\n",
    "\n",
    "for re_path in [\"7ch-all-lnvbs15o.csv\", \"5ch-all-20fh3z74.csv\", \"7ch-8batch-z0dv9mrl.csv\", \"5ch-8batch-lwpxanm3.csv\", \"5ch-32batch-qt94sfe8.csv\", \"7ch-32batch-0v3gpsxz.csv\"]:\n",
    "        lats = []\n",
    "        sizes = []\n",
    "        for p, predictor in enumerate(predictors):\n",
    "            # load predictor\n",
    "            NUM_FEATURES = int(re_path[0])\n",
    "            \n",
    "            tp = re_path.split(\"-\")[1]\n",
    "            if tp[0] == \"a\":\n",
    "                batch_s = 16\n",
    "            elif tp[0] == \"3\":\n",
    "                batch_s = 32\n",
    "            elif tp[0] == '8':\n",
    "                batch_s = 8\n",
    "            else:\n",
    "                print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                break\n",
    "            lats, sizes = check_latency(re_path, NUM_FEATURES, batch_s, predictor)        \n",
    "        \n",
    "            re = pd.read_csv(re_path)\n",
    "            print(\"-----------------------------\", len(re))\n",
    "            re[\"features\"] = NUM_FEATURES\n",
    "            re[\"batch_s\"] = batch_s\n",
    "            re[\"acc\"] = re.reward\n",
    "            re[\"latency\"] = lats\n",
    "            re[\"lat_std\"] = lat_stds\n",
    "            re[\"memory\"] = sizes\n",
    "            re[\"predictor\"] = predictor_names[p]\n",
    "\n",
    "            all_re = pd.concat([all_re, re]).reset_index(drop=True)\n",
    "            print(\"-------------------------------------------------\", len(all_re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a373586",
   "metadata": {},
   "outputs": [],
   "source": [
    "re = all_re\n",
    "re[\"memory\"] = re[\"memory\"]/1e6\n",
    "t = re.mutation[0].replace(\"'\", \"\\\"\")\n",
    "d = json.loads(t)\n",
    "dicts = re.mutation.apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\n",
    "\n",
    "for col in d.keys():\n",
    "    re[col] = [dt[col] for dt in dicts]\n",
    "re_fin = re[['trialJobId', 'features', 'batch_s', 'acc', 'latency', 'memory', 'predictor'] + list(d.keys())]\n",
    "re_fin.to_csv(\"fin_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
