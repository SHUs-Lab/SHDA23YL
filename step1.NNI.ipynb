{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d29d08cd-913c-4e69-8042-2af453509c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from nni.retiarii import model_wrapper\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "\n",
    "import nni\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "if num_gpus >= 2:\n",
    "    # Select the second GPU (index 1)\n",
    "    device = torch.device(\"cuda:1\")\n",
    "else:\n",
    "    # If there are not enough GPUs, use the first one (index 0) or CPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "093785c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set parameters here\n",
    "datapath = \"whole_data.npy\"\n",
    "labelpath = \"whole_label.npy\"\n",
    "NUM_FEATURES = 7\n",
    "batch_size = 16\n",
    "train_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1686a5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12068, 100, 100, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(datapath).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9221781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "@model_wrapper\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model_name = 'resnet'\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        num_channel_1 = nn.ValueChoice([32, 48, 64], label=\"num_channel\")\n",
    "        \n",
    "        kernel_sizes = nn.ValueChoice([3, 5], label=\"kernel_size\")\n",
    "        strides = nn.ValueChoice([1, 2], label=\"stride\")\n",
    "        paddings = nn.ValueChoice([1, 2, 3], label=\"padding\")\n",
    "        self.conv1 = nn.Conv2d(NUM_FEATURES, num_channel_1, kernel_size=kernel_sizes, stride=strides, padding=paddings, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_channel_1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        kernel_size_pool = nn.ValueChoice([2, 3], label=\"kernel_size_pool\")\n",
    "        stride_size_pool = nn.ValueChoice([1, 2], label=\"stride_size_pool\")\n",
    "        self.poolchoice = nn.LayerChoice([nn.MaxPool2d(kernel_size=kernel_size_pool, stride=stride_size_pool, padding=1),\n",
    "                                         nn.Identity()], label=\"poolchoice\")\n",
    "        \n",
    "        num_channel_2 = num_channel_1*2\n",
    "        num_channel_3 = num_channel_2*2\n",
    "        num_channel_4 = num_channel_3*2\n",
    "\n",
    "        ### layer1\n",
    "        self.block1 = self.make_block(num_channel_1, num_channel_1, 1)\n",
    "        self.block2 = self.make_block(num_channel_1, num_channel_1, 1)\n",
    "        ### layer2\n",
    "        self.block3 = self.make_block(num_channel_1, num_channel_2, 2)\n",
    "        self.block4 = self.make_block(num_channel_2, num_channel_2, 1)\n",
    "        ### layer3\n",
    "        self.block5 = self.make_block(num_channel_2, num_channel_3, 2)\n",
    "        self.block6 = self.make_block(num_channel_3, num_channel_3, 1)\n",
    "        ### layer4\n",
    "        self.block7 = self.make_block(num_channel_3, num_channel_4, 2)\n",
    "        self.block8 = self.make_block(num_channel_4, num_channel_4, 1)\n",
    "        \n",
    "        ### downsample\n",
    "        self.ds2 = nn.Sequential(nn.Conv2d(num_channel_1, num_channel_2, kernel_size=1, stride=2, bias=False),\n",
    "                                 nn.BatchNorm2d(num_channel_2))\n",
    "        self.ds3 = nn.Sequential(nn.Conv2d(num_channel_2, num_channel_3, kernel_size=1, stride=2, bias=False),\n",
    "                                 nn.BatchNorm2d(num_channel_3))\n",
    "        self.ds4 = nn.Sequential(nn.Conv2d(num_channel_3, num_channel_4, kernel_size=1, stride=2, bias=False),\n",
    "                                 nn.BatchNorm2d(num_channel_4))\n",
    "        \n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc = nn.Linear(num_channel_4, num_classes)\n",
    "\n",
    "    def make_block(self, inplanes, planes, stride=1):\n",
    "        conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        bn1 = nn.BatchNorm2d(planes)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        bn2 = nn.BatchNorm2d(planes)\n",
    "        basicblock = []\n",
    "        basicblock += [conv1, bn1, relu, conv2, bn2]\n",
    "        return nn.Sequential(*basicblock)\n",
    "           \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.poolchoice(x)\n",
    "        x1 = self.block1(x) + x\n",
    "        x1 = self.block2(x1) + x1\n",
    "        x2 = self.ds2(x1) + self.block3(x1)\n",
    "        x2 = self.block4(x2) + x2\n",
    "        x3 = self.ds3(x2) + self.block5(x2)\n",
    "        x3 = self.block6(x3) + x3\n",
    "        x4 = self.ds4(x3) + self.block7(x3)\n",
    "        x4 = self.block8(x4) + x4\n",
    "        x = self.adaptivepool(x4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "230875af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, device, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    n_samples = 0\n",
    "    n_correct = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader): \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Accuracy\n",
    "        _, predicted = outputs.max(axis=1)\n",
    "        n_samples += labels.size(0) \n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def test_epoch(model, device, test_loader):\n",
    "    model.eval()  \n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'======== Accuracy of the CNN: {acc} %')\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model_cls):\n",
    "    model = model_cls()\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    data = np.load(datapath)  # (num, 100, 100, 5)\n",
    "    labels = np.load(labelpath)  # (num,)\n",
    "    data = np.transpose(data, (0, 3, 1, 2))\n",
    "    \n",
    "    # Convert data and labels to torch tensors\n",
    "    data = torch.tensor(data, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "                   \n",
    "    # Define the number of folds for stratified k-fold\n",
    "    k_folds = 5\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    accuracy = 0\n",
    "                   \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(data, labels)):\n",
    "        # Split the dataset into training and validation sets\n",
    "        train_data = TensorDataset(data[train_idx], labels[train_idx])\n",
    "        val_data = TensorDataset(data[val_idx], labels[val_idx])\n",
    "\n",
    "        # Create DataLoader for training and validation sets\n",
    "        train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "                   \n",
    "        for epoch in range(train_epochs):\n",
    "            # train the model for one epoch\n",
    "            train_epoch(model, device, train_loader, criterion, optimizer, epoch)\n",
    "            # test the model for one epoch\n",
    "        accuracy += test_epoch(model, device, test_loader)\n",
    "        # call report intermediate result. Result can be float or dict\n",
    "        nni.report_intermediate_result(accuracy/(fold+1))\n",
    "        \n",
    "    cv_accuracy = accuracy/k_folds\n",
    "    # report final test result\n",
    "    nni.report_final_result(cv_accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de433bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model HERE\n",
    "model_space = ResNet()\n",
    "evaluator = FunctionalEvaluator(evaluate_model)\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "\n",
    "\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'resnet18_drainage_crx'\n",
    "\n",
    "exp_config.max_trial_number = 288\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "\n",
    "# Start webUI\n",
    "port = random.randint(1100,25000)\n",
    "print (\"running on port\")\n",
    "print(port)\n",
    "exp.run(exp_config, port)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_dict in exp.export_top_models(formatter='dict'):\n",
    "    print(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a33c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
